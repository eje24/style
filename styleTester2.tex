\documentclass{scrartcl}
\usepackage[pset,claimcolor=Emerald]{eje}


\setname{Ezra Erives}
\setpsetclass{18.404}
\setdefcolor{Emerald}

\setpsetstyle{series}


\title{Style File Test}
\begin{document}



\maketitle

\begin{abstract}
    This document contains three examples (colorbox, neutral, and standard lemma environments, respectively). Everything super preliminary lmao. Will eventually add a sans-serif font for the 'classic' computer modern \LaTeX\ look.

\end{abstract}

\section{Introduction}

\begin{theorem}
    test theorem
\end{theorem}
\begin{lemma}
    test lemma
\end{lemma}
\begin{proposition}
    test proposition
\end{proposition}
\begin{conjecture}
    test conjecture
\end{conjecture}
\begin{definition}
    test definition
\end{definition}
\begin{remark}
    test remark
\end{remark}
\begin{theorembox}
\end{theorembox}
\begin{propbox}
    this is a proposition!
\end{propbox}
\begin{defbox}
    test test test test test test test test test test test test test test test test test test test test test test test test test test test test 
\end{defbox}

\newpage

\subsection{Diagonalizability of $e^A$}
% \begin{problembox}{1}{Diagonalizability of $e^A$}
%     Show that $e^A$ is diagonalizable if and only if $A$ is.
% \end{problembox}
\begin{solution} There are two direction to establish. We start by showing that if $A$ is diagonalizable, then so is $e^A$.
    \begin{claimbox}
    If $v$ is an eigenvector of $A$ with eigenvalue $\lambda\in \CC$, then $v$ is an eigenvector of $e^A$ with eigenvalue $e^\lambda$.
    \end{claimbox}
    \begin{tproof}
    Suppose $v$ is an eigenvalue of $A$ with eigenvalue $\lambda$. Then 
    \[e^Av=\sum_{k=0}^{\infty}\frac{1}{k!}A^kv=\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}v=e^\lambda v\]
    Therefore, $v$ is an eigenvector of $e^A$
     with eigenvalue $e^\lambda$.
     \end{tproof}
    
    \begin{claimbox}
    If $A$ is diagonalizable, then so is $e^A$.
    \end{claimbox}
    \begin{tproof}
    If $A$ is diagonalizable, then there exists some basis $\mathcal{B}$ of eigenvectors. By the first claim, the elements of $\mathcal{B}$ are eigenvectors of $e^A$ as well, and so $\mathcal{B}$ is a basis of eigenvectors of $e^A$ which is therefore diagonalizable.
    \end{tproof}
    
    The opposite direction is slightly trickier - not every eigenvector of $e^A$ is an eigenvector of $A$. We show however, that these additional eigenvectors (should they exist) admit a simple description. 
    
    \begin{claimbox}
    If $v$ is an eigenvector of $e^A$ with eigenvalue $\lambda$, then $v$ is a linear combination $v_1+\dots +v_k$ of eigenvectors of $A$, whose associated eigenvalues $\lambda_1\dots \lambda_k$ are distinct and satisfy $e^{\lambda_1}=\dots=e^{\lambda_k}=\lambda$.
    \end{claimbox}
        
    \begin{tproof}
    Without loss of generality, we may assume that $A$ is in Jordan canonical form. This is justified because the matrix exponential (as a linear map) is independent of basis (part (f) of the previous homework problem). Let $J_1,J_2,\dots, J_k$ be the Jordan blocks of $A$, corresponding to $A$-invariant subspaces $V_1,V_2,\dots, V_k$ of $V$. Then $e^A$ is block diagonal, with blocks given by the exponentials of the Jordan blocks. In particular, as $V$ is the direct sum of the $V_i$, any eigenvector $v$ of $e^A$ with eigenvalue $\lambda$ can be written as the sum $v_1+\dots + v_n$, where $v_i\in V_i$ is either zero, or an eigenvector of $e^A$ with eigenvalue $\lambda$. It is therefore sufficient to prove the claim when $A$ is replaced by the arbitrary Jordan block $J_i$, with eigenvalue $\lambda_i$.
    
    Write $J_i=\lambda_iI+N$, where $N$ consists of the off-diagonal entries of $J_i$ (i.e. the ones above the main diagonal). Then $\lambda_i I$ and $N$ commute, so by part (c) of the previous question $e^{J_i}=e^{\lambda_iI}e^N=(e^{\lambda_i}I)e^N$. Notice that $N$ is nilpotent, with $N^m=0$, where $m$ is the size of the matrix $J_i$. It follows that $e^N=\sum_{t=0}^\infty \tfrac{1}{t!}N^t=\sum_{t=0}^{m-1} \tfrac{1}{t!}N^t$. We see then that
    \[e^{J_i}=(e^{\lambda_i}I)e^N=(e^{\lambda_i}I)
    \begin{bmatrix}
    1 & 1 & \tfrac{1}{2} & \hdots & \tfrac{1}{(m-1)!} \\
    & 1 & & & \vdots \\
    & & \ddots & & \tfrac{1}{2} \\
    & & & 1 & 1 \\
    & & & & 1\\
    \end{bmatrix}.\]
    From this we see that the only eigenvalue of $e^{J_i}$ is $e^{\lambda_i}$, and that $\ker(e^{J_i}-e^{\lambda_i}I)$ is simply the span of the first basis vector (which can be verified by subtracting off $I$ and observing that every component except the first in the coordinate vector of a solution is forced to be zero). This first basis vector is none other than the eigenvector of $A$ with eigenvector $\lambda_i$ corresponding to the Jordan block $J_i$, and so we are done.
    \end{tproof}
    
    For $\lambda\in \CC$, let $K_\lambda$ and $K_\lambda'$ denote the possible empty $\lambda$-eigenspaces of $A$ and $e^A$ respectively. It follows then from the first claim that 
    \[K_\lambda'\supseteq\bigoplus_{e^{\lambda'}=\lambda} K_{\lambda'}.\]
    By the previous claim, the containment is in fact an equality.
    \begin{claimbox}
    If $e^A$ is diagonalizable, then so is $A$, from which the next claim follows.
    \end{claimbox}
    \begin{tproof}
    If $e^A$ is diagonanizable, then \[\dim V=\sum_\lambda \dim K_\lambda'=\sum_\lambda \sum_{e^{\lambda'}=\lambda}\dim K_{\lambda'}=\sum_{\lambda}\dim K_\lambda\] and so $V$ is the direct sum of the non-empty $K_\lambda$'s, and we may combine bases for each such $K_\lambda$ to obtain a basis of eigenvectors of $V$. Thus, $A$ is diagonalizable, as desired.
    \end{tproof}
    
    Both directions are proven, and so we are done.
    \end{solution}

\newpage
\subsection{Silvester's Criterion}
\begin{solution}
    We prove the result for the general case, in which the matrix is Hermitian. The real case follows by viewing symmetric matrices as Hermitian with real entries. Apparently, the upper left $k\times k$ sub-matrices have a name - \textit{leading principal minors}. We'll use this term from now on in reference to the determinants of these sub-matrices. We proceed via induction. The base case is clear: the matrix $\begin{bmatrix} z \end{bmatrix}$ is positive definite if and only if $z$ (the determinant) is a positive real number. Now suppose that the claim holds for all $(n-1) \times (n-1)$ Hermitian matrices. We demonstrate that the claim holds for $n\times n$ matrices as well. Let $T=\begin{bmatrix} P & v \\ v^\ast & z \end{bmatrix}$ be an $n\times n$ Hermitian matrix, where $P$ is an $(n-1) \times (n-1)$ Hermitian matrix, and $z$ is some complex number. For unitary $Q$, we have that
    \[\begin{bmatrix} Q^\ast & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} P & v \\ v^\ast & z \end{bmatrix} \begin{bmatrix} Q & 0 \\ 0 & 1 \end{bmatrix}=\begin{bmatrix} {Q^\ast} P Q & Q^\ast v \\ v^\ast Q & z \end{bmatrix}=T'.\]
    Observe that $T'$ is Hermitian, and is positive-definite if and only if $T$ is positive definite, as conjugation by an unitary matrix preserves definiteness (simply a change of basis). Additionally, they have the same determinant. By similar reasoning, ${Q^\ast} P Q$ is positive definite if and only if $P$ is, and by our inductive hypothesis, we see the leading principle minors of ${Q^\ast} P Q$ are positive if and only if the leading principle minors of $P$ are positive. Therefore, it is sufficient to prove the result for $T'$. By the Spectral theorem, since $P$ is Hermitian, we may choose $Q$ so that $Q^\ast PQ$ is diagonal. Writing the diagonal entries as $\lambda_1 \dots \lambda_n$, and $Q^\ast v$ as $\begin{bmatrix} v_1 \dots v_{n-1} \end{bmatrix}$ we find that 
    \[T'=\begin{bmatrix} 
    \lambda_1 & & & v_1 \\
        & \ddots & & \vdots \\
        & & \lambda_{n-1} & v_{n-1} \\
    \overline{v_1} & \hdots & \overline{v_{n-1}} & z \\
    \end{bmatrix}\]

    We now consider each direction:
    \begin{itemize}
        \item \textbf{$T'$ has positive leading principal minors implies $T'$ is positive-definite:} In this case, for $1\le k <n$, the $k$-th principal minor is the product $\prod_{i=1}^k \lambda_i$, and so for all such $k$, the eigenvalue $\lambda_k$ is positive. The $n$-th leading principal minor is simply the determinant $\det T'$ itself. Thus
        \[\det T'=\lambda z - \sum_{i=1}^{n-1} \frac{\lambda v_i\overline{v_i}}{\lambda_i}=\lambda\left(z - \sum_{i=1}^{n-1} \frac{ \abs{v_i}^2}{\lambda_i}\right)>0.\]
        where $\lambda=\prod_{i=1}^{n-1}\lambda_i$. As the $\lambda_i$ are all positive real numbers, we see that $\lambda>0$, and so $z - \sum_{i=1}^{n-1} \frac{ \abs{v_i}^2}{\lambda_i}>0$. Note that as $T'$ is Hermitian, $z$ must be real, as must the $\abs{v_i}^2$ terms. We'll now use this inequality, to demonstrate that $T'$ is positive definite. Indeed, let $w=\sum_{i=1}^n c_ie_i$ be non-zero, where the $e_i$ constitute the basis with respect to which the matrix $T'$ is written. Without loss of generality, assume that $c_n=1$. Then, completing the square we see that 
        \[w^\ast T' w=\sum_{i=1}^{n-1} c_i^2\lambda_i+\sum_{i=1}^{n-1}c_i(v_i+\overline{v_i})+z=\sum_{i=1}^{n-1} \left(c_i\sqrt{\lambda_i} + \frac{\Re (v_i)}{\sqrt{\lambda_i}}\right)^2 + \left(z-\sum_{i=1}^{n-1}\frac{\Re (v_i)^2}{\lambda_i} \right).\]
        Note that $\Re (v_i)^2\le \abs{v_i}^2$, with equality holding when $v_i\in \RR$. It follows that
        \[\sum_{i=1}^{n-1} \left(c_i\sqrt{\lambda_i} + \frac{\Re (v_i)}{\sqrt{\lambda_i}}\right)^2 + \left(z-\sum_{i=1}^{n-1}\frac{\Re (v_i)^2}{\lambda_i} \right)\ge \left(z-\sum_{i=1}^{n-1}\frac{\Re (v_i)^2}{\lambda_i} \right) \ge \left(z-\sum_{i=1}^{n-1}\frac{\abs{v_i}^2}{\lambda_i} \right)>0,\]
        and so $w^\ast T' w>0$, as desired. Thus, $T'$ is positive definite.
        
        \item \textbf{$T'$ is positive definite implies that $T'$ has positive principal minors:} This  direction is significantly shorter. As $T'$ is positive, its upper left $(n-1)\times (n-1)$ submatrix is positive definite as well, implying by our induction hypothesis that the for $1\le k < n$, the $k$-th leading principal minor is positive. Finally, as $T'$ is positive definite, all of its eigenvalues are positive, and so $\det T'>0$, as desired.
    \end{itemize}
    We conclude that $T$ is positive definite if and only if its leading principal minors are strictly positive, completing our inductive step. As discussed before, the real case is a consequence of what we have just proven.
\end{solution}

\newpage
\subsection{Conjugacy classes in $M$}

\begin{solution}
    Isometries of the plane can be thought of as the symmetries of some sheet of paper. If some isometry is obtained from a second by rotating, translating, or flipping the sheet of paper, then these two isometries are simply two ways of viewing the same symmetry. Indeed, the only truly distinguishing aspects of an isometry are the \cbold{magnitude of translation}, the \cbold{magnitude of rotation}, and the \cbold{presence of reflection}. We make this precise. As usual, let $r$ denote the reflection about the $x$-axis, and let $C(g)$ denote the conjugacy class of some element $g\in G$. When convenient, we let $a\sim b$ mean that $a$ and $b$ are conjugate. We start with \cbold{translations}.
    \begin{lemma}
    For $v\in \RR^2$, the conjugacy class of the translation $t_v$ is the set $C'(t_v)=\{t_{v'}\mid \abs{v'}=\abs{v}\}$.
    \end{lemma}
    \begin{tproof}
    Let $C'(t_v)=\{t_{v'}\mid \abs{v'}=\abs{v}\}$. We wish to show $C'(t_v)=C(t_v)$. Conjugation by any translation fixes $t_v$, while conjugation by some $m\in O_2$ sends $t_v$ to $t_u$ with $\abs{v}=\abs{u}$. In both cases, the image is in $C'(t_v)$, and so $C(t_v)\subseteq C'(t_v)$. Conversely, the elements of $C'(v)$ are translations by rotated versions of $v$, which are obtained by conjugating $t_v$ by the appropriate rotation. Thus, $C'(t_v)\subseteq C(t_v)$, and so $C(t_v)=C'(t_v)=\{t_{v'}\mid \abs{v'}=\abs{v}\}$.
    \end{tproof}

    We now turn to \cbold{rotations}. That is, isometries $g$ for which the usual map $\phi: M_2 \to O_2$ carries $g$ to some rotation.
    \begin{lemma}
    For $v\in \RR^2$ and non-zero angle $\theta$, the conjugacy class of the rotation $t_v\rho_\theta$ is the set $\{t_u\rho_\gamma| u\in \RR^2, \gamma=\theta \text{ or } -\theta\}$.
    \end{lemma}
    \begin{tproof} As before, let $C'(t_v\rho_\theta)=\{t_u\rho_\gamma| u\in \RR^2, \gamma=\theta \text{ or } -\theta\}$. Conjugating by the appropriate translation yields $t_v\rho_\theta\sim \rho_\theta$, and so $C(t_v\rho_\theta)=C(\rho_\theta)$. Observe that $\rho_\theta$ is fixed under conjugation by any other rotation $\rho_\gamma$, and that conjugating by $r$ yields $\rho_{-\theta}$. It follows that $C(\rho_\theta)\cap O_2=\{\rho_{\theta},\rho_{-\theta}\}$, with the union of the images of these two rotations under conjugation by all translations being the set $C'(t_v\rho_\theta)$. Thus, $C'(t_v\rho_\theta)\subseteq C(t_v\rho_\theta)$. Conversely, if $t_um\in C(t_v\rho_\theta)$, for $m\in O_2$, then $m\in \{\rho_{\theta},\rho_{-\theta}\}$, and so $C(t_v\rho_\theta)\subseteq C'(t_v\rho_\theta)$, from which equality follows.
    \end{tproof}

    Finally, we address \cbold{glide reflections}. Let the \textit{glide component} of a glide reflection be the projection of the translation vector onto the axis of reflection.
    \begin{lemma}
    For $v\in \RR^2$, and angle $\theta$, the conjugacy class of the glide reflection $t_v\rho_\theta r$ is the set of glide reflections with glide component of equal magnitude.
    \end{lemma}
    \textbf{Note:} This final case covers both glide reflections and regular reflections. Regular reflections are the special case when $v$ is parallel to the axis of reflection.
    \begin{tproof}
    Let $\ell$ be the axis of reflection of $t_v\rho_\theta r$. Write $v=u+w$, with $u\perp \ell$ and $w\parallel \ell$. Conjugation by any $m\in O_2$ sends $t_{u+w}\rho_\theta r$ to $t_{u'+w'}\rho_\theta r$, a glide reflection about the line $\ell'$, where $\abs{u'}=\abs{u}$, $\abs{w'}=\abs{w}$, $u'\perp \ell'$, and $w'\parallel \ell'$. Letting $v=u'+w'$ follows that
    \[\abs{\proj_\ell(v)}=\abs{u}=\abs{u'}=\abs{\proj_{\ell'}(v')}.\] Thus, conjugating by any such $m$ preserves the magnitude of the glide component. Furthermore, observe that $t_w$ commutes with $\rho_\theta r$, while $t_u\rho_\theta r=\rho_\theta rt_{-u}$. It follows that conjugating by $t_w$ fixes $t_v\rho_\theta r$ while conjugating by $t_u$ simply translates the axis of reflection in the direction parallel to $u$, in both cases preserving the glide component. As any $k\in \RR^2$ is a linear combination of $u$ and $w$, conjugating by any translation again preserves glide magnitude, and combining this with the result about $m\in O_2$, gives that conjugating by any isometry preserves glide magnitude. It follows that $C(t_v\rho_\theta r)$ contains only glide reflections of the same glide magnitude as $t_v\rho_\theta r$.
    
    Conversely, suppose that $g$ is some other glide reflection with the same glide magnitude, and with axis $\ell_g$. To finish, we must show that $g\in C(t_v\rho_\theta r)$. Take any isometry carrying the $\ell_g$ to $\ell$. Then conjugating $g$ by that isometry gives a glide reflection $g'\sim g$ about $\ell$ with the same magnitude. There are only two such glide reflections about $\ell$, both in $C(t_v\rho_\theta r)$. It follows that $g\sim g'\in C(t_v\rho_\theta r)$, and so $C(t_v\rho_\theta r)$ contains $g$, as desired.
    \end{tproof}

    We collect our results below. Viewing the identity as the zero-translation, the conjugacy classes of $M$ are as follows:
    \begin{itemize}
        \item \cbold{Translations:} For every $t\ge 0$, the set of translations $\{t_{v'}\mid \abs{v'}=\abs{v}\}$ is a conjugacy class.
        \item \cbold{Rotations:} For every $\theta\in (0,\pi]$, the set of rotations $\{t_u\rho_\gamma| u\in \RR^2, \gamma=\theta \text{ or } -\theta\}$ is a conjugacy class.
        \item \cbold{(Glide) Reflections:} For every $t\ge 0$, the set of glide reflections whose glide component has magnitude $t$ is a conjugacy class.
    \end{itemize}
    \end{solution}
        
\end{document}



